{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's first load the data and take a look at what we have.\n",
    "df = pd.read_csv('heathrow_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'], \n",
    "               axis=1,\n",
    "              inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>Hum</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.12</td>\n",
       "      <td>59.75</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>58.67</td>\n",
       "      <td>21.35</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.395833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.04</td>\n",
       "      <td>73.87</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.83</td>\n",
       "      <td>25.76</td>\n",
       "      <td>34.37</td>\n",
       "      <td>14.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194.00</td>\n",
       "      <td>59.39</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>65.33</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36.05</td>\n",
       "      <td>20.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.27</td>\n",
       "      <td>68.19</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.00</td>\n",
       "      <td>16.71</td>\n",
       "      <td>42.57</td>\n",
       "      <td>22.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.16</td>\n",
       "      <td>78.65</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>59.58</td>\n",
       "      <td>26.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>17.279167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>85.24</td>\n",
       "      <td>40.98</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>84.79</td>\n",
       "      <td>10.20</td>\n",
       "      <td>25.35</td>\n",
       "      <td>7.420833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>163.94</td>\n",
       "      <td>37.20</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>91.63</td>\n",
       "      <td>6.15</td>\n",
       "      <td>27.77</td>\n",
       "      <td>15.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>282.06</td>\n",
       "      <td>58.82</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "      <td>94.25</td>\n",
       "      <td>17.17</td>\n",
       "      <td>32.50</td>\n",
       "      <td>13.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>147.20</td>\n",
       "      <td>37.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>86.63</td>\n",
       "      <td>8.21</td>\n",
       "      <td>25.78</td>\n",
       "      <td>6.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>74.63</td>\n",
       "      <td>37.61</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "      <td>78.79</td>\n",
       "      <td>8.37</td>\n",
       "      <td>25.99</td>\n",
       "      <td>9.929167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp  wdir  wspd    pres    Hum  \\\n",
       "0       232.12       59.75  18.7  15.5  22.6   0.0     2  12.5  1023.9  58.67   \n",
       "1       168.04       73.87  18.6  13.9  23.4   0.0     1  10.1  1021.8  65.83   \n",
       "2       194.00       59.39  19.2  13.7  24.4   0.0     2   8.4  1021.5  65.33   \n",
       "3       343.27       68.19  20.6  15.7  26.8   0.0     2  10.1  1021.8  65.00   \n",
       "4       190.16       78.65  21.8  14.9  27.8   0.0     3  10.2  1020.0  59.58   \n",
       "..         ...         ...   ...   ...   ...   ...   ...   ...     ...    ...   \n",
       "575      85.24       40.98   3.2   0.1   5.6   0.5     2  11.3  1019.5  84.79   \n",
       "576     163.94       37.20  -0.1  -1.7   2.1   0.0     4  10.6  1018.6  91.63   \n",
       "577     282.06       58.82   0.1  -2.1   2.6   0.0     3   6.6  1026.4  94.25   \n",
       "578     147.20       37.50   4.8  -0.8   8.3   0.5     3  14.8  1020.0  86.63   \n",
       "579      74.63       37.61   5.3   2.2   8.1   5.3     4  12.8  1023.6  78.79   \n",
       "\n",
       "        NO    NO2       PM10  \n",
       "0    21.35  27.00  12.395833  \n",
       "1    25.76  34.37  14.937500  \n",
       "2    15.23  36.05  20.891667  \n",
       "3    16.71  42.57  22.316667  \n",
       "4    26.03  38.74  17.279167  \n",
       "..     ...    ...        ...  \n",
       "575  10.20  25.35   7.420833  \n",
       "576   6.15  27.77  15.304167  \n",
       "577  17.17  32.50  13.537500  \n",
       "578   8.21  25.78   6.412500  \n",
       "579   8.37  25.99   9.929167  \n",
       "\n",
       "[577 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Nox_tropo'], axis=1).values\n",
    "y = df['Nox_tropo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "n_hours = 1\n",
    "n_features = 13\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours , 3)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38]], axis=1, inplace=True)\n",
    "# print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var1(t-1)', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var5(t-1)',\n",
       "       'var6(t-1)', 'var7(t-1)', 'var8(t-1)', 'var9(t-1)', 'var10(t-1)',\n",
       "       'var11(t-1)', 'var12(t-1)', 'var13(t-1)', 'var1(t+2)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 13) 460 (460,)\n",
      "(460, 1, 13) (460,) (114, 1, 13) (114,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "#80% training data\n",
    "n_train_hours = 460\n",
    "train = values[:n_train_hours]\n",
    "test = values[n_train_hours:]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# train = data.values[:459]\n",
    "# test = data.values[459:]\n",
    "\n",
    "# # Separate input and output\n",
    "# train_X, train_y = train[:, :-1], train[:, -1]\n",
    "# test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# # Reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# # Print all shapes\n",
    "# train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape[0], train_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "154/154 - 3s - loss: 0.0146 - val_loss: 0.0270\n",
      "Epoch 2/50\n",
      "154/154 - 0s - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 3/50\n",
      "154/154 - 0s - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 4/50\n",
      "154/154 - 0s - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      "154/154 - 0s - loss: 8.8435e-04 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "154/154 - 1s - loss: 7.2948e-04 - val_loss: 0.0019\n",
      "Epoch 7/50\n",
      "154/154 - 1s - loss: 5.8782e-04 - val_loss: 0.0016\n",
      "Epoch 8/50\n",
      "154/154 - 0s - loss: 4.9040e-04 - val_loss: 0.0013\n",
      "Epoch 9/50\n",
      "154/154 - 0s - loss: 4.1302e-04 - val_loss: 0.0012\n",
      "Epoch 10/50\n",
      "154/154 - 0s - loss: 3.5986e-04 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "154/154 - 0s - loss: 3.2157e-04 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "154/154 - 0s - loss: 2.8872e-04 - val_loss: 9.8966e-04\n",
      "Epoch 13/50\n",
      "154/154 - 0s - loss: 2.7002e-04 - val_loss: 9.4271e-04\n",
      "Epoch 14/50\n",
      "154/154 - 0s - loss: 2.5286e-04 - val_loss: 8.8397e-04\n",
      "Epoch 15/50\n",
      "154/154 - 0s - loss: 2.3644e-04 - val_loss: 8.1421e-04\n",
      "Epoch 16/50\n",
      "154/154 - 0s - loss: 2.2423e-04 - val_loss: 7.7568e-04\n",
      "Epoch 17/50\n",
      "154/154 - 0s - loss: 2.1072e-04 - val_loss: 7.3474e-04\n",
      "Epoch 18/50\n",
      "154/154 - 0s - loss: 1.9897e-04 - val_loss: 6.8866e-04\n",
      "Epoch 19/50\n",
      "154/154 - 0s - loss: 1.8951e-04 - val_loss: 6.5648e-04\n",
      "Epoch 20/50\n",
      "154/154 - 0s - loss: 1.8131e-04 - val_loss: 6.4128e-04\n",
      "Epoch 21/50\n",
      "154/154 - 0s - loss: 1.7157e-04 - val_loss: 6.5538e-04\n",
      "Epoch 22/50\n",
      "154/154 - 0s - loss: 1.6163e-04 - val_loss: 6.2386e-04\n",
      "Epoch 23/50\n",
      "154/154 - 0s - loss: 1.6150e-04 - val_loss: 6.3582e-04\n",
      "Epoch 24/50\n",
      "154/154 - 0s - loss: 1.5115e-04 - val_loss: 6.1247e-04\n",
      "Epoch 25/50\n",
      "154/154 - 0s - loss: 1.4442e-04 - val_loss: 6.2350e-04\n",
      "Epoch 26/50\n",
      "154/154 - 0s - loss: 1.3779e-04 - val_loss: 5.9132e-04\n",
      "Epoch 27/50\n",
      "154/154 - 0s - loss: 1.3044e-04 - val_loss: 5.6360e-04\n",
      "Epoch 28/50\n",
      "154/154 - 0s - loss: 1.2733e-04 - val_loss: 5.1612e-04\n",
      "Epoch 29/50\n",
      "154/154 - 0s - loss: 1.1937e-04 - val_loss: 4.8027e-04\n",
      "Epoch 30/50\n",
      "154/154 - 0s - loss: 1.1430e-04 - val_loss: 4.5635e-04\n",
      "Epoch 31/50\n",
      "154/154 - 0s - loss: 1.0847e-04 - val_loss: 4.0791e-04\n",
      "Epoch 32/50\n",
      "154/154 - 0s - loss: 1.0672e-04 - val_loss: 3.9943e-04\n",
      "Epoch 33/50\n",
      "154/154 - 0s - loss: 1.0194e-04 - val_loss: 3.4079e-04\n",
      "Epoch 34/50\n",
      "154/154 - 0s - loss: 9.6749e-05 - val_loss: 3.3343e-04\n",
      "Epoch 35/50\n",
      "154/154 - 0s - loss: 9.2191e-05 - val_loss: 3.0205e-04\n",
      "Epoch 36/50\n",
      "154/154 - 0s - loss: 9.6047e-05 - val_loss: 2.7840e-04\n",
      "Epoch 37/50\n",
      "154/154 - 0s - loss: 9.2692e-05 - val_loss: 2.6084e-04\n",
      "Epoch 38/50\n",
      "154/154 - 0s - loss: 8.8172e-05 - val_loss: 2.5132e-04\n",
      "Epoch 39/50\n",
      "154/154 - 0s - loss: 7.9681e-05 - val_loss: 2.1109e-04\n",
      "Epoch 40/50\n",
      "154/154 - 0s - loss: 9.1759e-05 - val_loss: 2.1564e-04\n",
      "Epoch 41/50\n",
      "154/154 - 0s - loss: 7.1392e-05 - val_loss: 1.9464e-04\n",
      "Epoch 42/50\n",
      "154/154 - 0s - loss: 7.4510e-05 - val_loss: 1.7731e-04\n",
      "Epoch 43/50\n",
      "154/154 - 0s - loss: 8.2113e-05 - val_loss: 1.7789e-04\n",
      "Epoch 44/50\n",
      "154/154 - 0s - loss: 7.4799e-05 - val_loss: 1.6120e-04\n",
      "Epoch 45/50\n",
      "154/154 - 0s - loss: 7.7278e-05 - val_loss: 1.6043e-04\n",
      "Epoch 46/50\n",
      "154/154 - 0s - loss: 6.8028e-05 - val_loss: 1.5319e-04\n",
      "Epoch 47/50\n",
      "154/154 - 0s - loss: 6.8866e-05 - val_loss: 1.4864e-04\n",
      "Epoch 48/50\n",
      "154/154 - 0s - loss: 6.1792e-05 - val_loss: 1.4509e-04\n",
      "Epoch 49/50\n",
      "154/154 - 0s - loss: 5.2822e-05 - val_loss: 1.4522e-04\n",
      "Epoch 50/50\n",
      "154/154 - 0s - loss: 5.1595e-05 - val_loss: 1.3654e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(13, input_shape=(train_X.shape[1], train_X.shape[2]),activation='relu'))\n",
    "model.add(Dense(38, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=3, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 7.486\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -12:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -12:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.433829674380095"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(inv_y,inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.053047459993405"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(inv_y,inv_yhat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13-38-1 Test RMSE: 62.006\n",
    "\n",
    "13-68-1 Test RMSE: 68.752"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 61-1 Test RMSE: Test RMSE: 63.163\n",
    "\n",
    "13-40-1 Test RMSE: 67.366\n",
    "\n",
    "13-100-1 Test RMSE: 65.965\n",
    "\n",
    "13- -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
