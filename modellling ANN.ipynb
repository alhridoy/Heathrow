{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's first load the data and take a look at what we have.\n",
    "df = pd.read_csv('Heathrow_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/7/18</td>\n",
       "      <td>232.1240</td>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/7/18</td>\n",
       "      <td>168.0445</td>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/7/18</td>\n",
       "      <td>194.0030</td>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/7/18</td>\n",
       "      <td>343.2730</td>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/7/18</td>\n",
       "      <td>190.1570</td>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>6/1/21</td>\n",
       "      <td>85.2440</td>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>7/1/21</td>\n",
       "      <td>163.9400</td>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>9/1/21</td>\n",
       "      <td>282.0585</td>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>16/1/21</td>\n",
       "      <td>147.2020</td>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>17/1/21</td>\n",
       "      <td>74.6270</td>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd  \\\n",
       "0    10/7/18   232.1240   59.746988  18.7  15.5  22.6   0.0   75.0  12.5   \n",
       "1    11/7/18   168.0445   73.870523  18.6  13.9  23.4   0.0   45.0  10.1   \n",
       "2    12/7/18   194.0030   59.394005  19.2  13.7  24.4   0.0   52.0   8.4   \n",
       "3    13/7/18   343.2730   68.192323  20.6  15.7  26.8   0.0  135.0  10.1   \n",
       "4    14/7/18   190.1570   78.645600  21.8  14.9  27.8   0.0  177.0  10.2   \n",
       "..       ...        ...         ...   ...   ...   ...   ...    ...   ...   \n",
       "772   6/1/21    85.2440   40.983786   3.2   0.1   5.6   0.5   89.0  11.3   \n",
       "773   7/1/21   163.9400   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6   \n",
       "774   9/1/21   282.0585   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6   \n",
       "775  16/1/21   147.2020   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8   \n",
       "776  17/1/21    74.6270   37.605938   5.3   2.2   8.1   5.3  269.0  12.8   \n",
       "\n",
       "       pres  \n",
       "0    1023.9  \n",
       "1    1021.8  \n",
       "2    1021.5  \n",
       "3    1021.8  \n",
       "4    1020.0  \n",
       "..      ...  \n",
       "772  1019.5  \n",
       "773  1018.6  \n",
       "774  1026.4  \n",
       "775  1020.0  \n",
       "776  1023.6  \n",
       "\n",
       "[581 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'], \n",
    "               axis=1,\n",
    "              inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nox_tropo  Nox_ground        tavg        tmin        tmax        prcp  \\\n",
      "count  581.000000  581.000000  581.000000  581.000000  581.000000  581.000000   \n",
      "mean   154.640394   87.475530   11.952324    8.132702   15.979346    1.799312   \n",
      "std     85.091413   53.594039    5.628182    5.180414    6.802516    3.711278   \n",
      "min    -85.357000    7.343970   -0.300000   -5.200000    2.100000    0.000000   \n",
      "25%     97.823000   53.771526    7.600000    4.300000   10.500000    0.000000   \n",
      "50%    136.237500   76.813392   11.000000    7.500000   14.600000    0.000000   \n",
      "75%    190.157000  107.551883   16.700000   12.100000   21.600000    1.800000   \n",
      "max    643.546000  373.493696   28.600000   20.000000   37.200000   34.000000   \n",
      "\n",
      "             wdir        wspd         pres  \n",
      "count  581.000000  581.000000   581.000000  \n",
      "mean   197.080895   15.085026  1015.459552  \n",
      "std     69.440860    6.601353    11.312636  \n",
      "min     16.000000    3.500000   977.500000  \n",
      "25%    159.000000   10.100000  1008.800000  \n",
      "50%    216.000000   13.900000  1016.200000  \n",
      "75%    247.000000   18.900000  1023.000000  \n",
      "max    339.000000   39.200000  1047.700000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df=df\n",
    "print(df.describe()) #to understand the dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      232.1240\n",
       "1      168.0445\n",
       "2      194.0030\n",
       "3      343.2730\n",
       "4      190.1570\n",
       "         ...   \n",
       "772     85.2440\n",
       "773    163.9400\n",
       "774    282.0585\n",
       "775    147.2020\n",
       "776     74.6270\n",
       "Name: Nox_tropo, Length: 581, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Nox_tropo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Nox_tropo  Nox_ground        tavg        tmin        tmax        prcp  \\\n",
      "count  581.000000  581.000000  581.000000  581.000000  581.000000  581.000000   \n",
      "mean   154.640394   87.475530   11.952324    8.132702   15.979346    1.799312   \n",
      "std     85.091413   53.594039    5.628182    5.180414    6.802516    3.711278   \n",
      "min    -85.357000    7.343970   -0.300000   -5.200000    2.100000    0.000000   \n",
      "25%     97.823000   53.771526    7.600000    4.300000   10.500000    0.000000   \n",
      "50%    136.237500   76.813392   11.000000    7.500000   14.600000    0.000000   \n",
      "75%    190.157000  107.551883   16.700000   12.100000   21.600000    1.800000   \n",
      "max    643.546000  373.493696   28.600000   20.000000   37.200000   34.000000   \n",
      "\n",
      "             wdir        wspd         pres  \n",
      "count  581.000000  581.000000   581.000000  \n",
      "mean   197.080895   15.085026  1015.459552  \n",
      "std     69.440860    6.601353    11.312636  \n",
      "min     16.000000    3.500000   977.500000  \n",
      "25%    159.000000   10.100000  1008.800000  \n",
      "50%    216.000000   13.900000  1016.200000  \n",
      "75%    247.000000   18.900000  1023.000000  \n",
      "max    339.000000   39.200000  1047.700000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df=df\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will be a pandas dataframe of all columns except meantempm\n",
    "X = df[[col for col in df.columns if col != 'Nox_tropo']]\n",
    "\n",
    "# y will be a pandas series of the meantempm\n",
    "y = df['Nox_tropo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 8) (464,) (117,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train  = y_train.astype(int)\n",
    "y_test  = y_test.astype(int)\n",
    "batch_size =len(X_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resclae\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Train\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "# test\n",
    "X_test_scaled = scaler.fit_transform(X_test.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('x', shape=X_train_scaled.shape[1:])]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='x', shape=(8,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hridoy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "581/581 [==============================] - 0s 702us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "581/581 [==============================] - 0s 208us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "581/581 [==============================] - 0s 280us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "581/581 [==============================] - 0s 244us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "581/581 [==============================] - 0s 351us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "581/581 [==============================] - 0s 244us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "581/581 [==============================] - 0s 185us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "581/581 [==============================] - 0s 198us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "581/581 [==============================] - 0s 312us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "581/581 [==============================] - 0s 261us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "581/581 [==============================] - 0s 232us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "581/581 [==============================] - 0s 179us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "581/581 [==============================] - 0s 174us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "581/581 [==============================] - 0s 359us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "581/581 [==============================] - 0s 208us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "581/581 [==============================] - 0s 208us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "581/581 [==============================] - 0s 216us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "581/581 [==============================] - 0s 211us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "581/581 [==============================] - 0s 237us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "581/581 [==============================] - 0s 306us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "581/581 [==============================] - 0s 238us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "581/581 [==============================] - 0s 215us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "581/581 [==============================] - 0s 261us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "581/581 [==============================] - 0s 196us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "581/581 [==============================] - 0s 219us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "581/581 [==============================] - 0s 195us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "581/581 [==============================] - 0s 201us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "581/581 [==============================] - 0s 245us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "581/581 [==============================] - 0s 206us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "581/581 [==============================] - 0s 186us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "581/581 [==============================] - 0s 255us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "581/581 [==============================] - 0s 211us/step - loss: -2449.3943 - acc: 0.0000e+00 0s - loss: -2457.3494 - acc: 0.0000e+\n",
      "Epoch 35/150\n",
      "581/581 [==============================] - 0s 227us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "581/581 [==============================] - 0s 173us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "581/581 [==============================] - 0s 195us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "581/581 [==============================] - 0s 210us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "581/581 [==============================] - 0s 243us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "581/581 [==============================] - 0s 203us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 41/150\n",
      "581/581 [==============================] - 0s 307us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "581/581 [==============================] - 0s 221us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 43/150\n",
      "581/581 [==============================] - 0s 188us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "581/581 [==============================] - 0s 189us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "581/581 [==============================] - 0s 202us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 46/150\n",
      "581/581 [==============================] - 0s 193us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 47/150\n",
      "581/581 [==============================] - 0s 183us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 48/150\n",
      "581/581 [==============================] - 0s 149us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 49/150\n",
      "581/581 [==============================] - 0s 247us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 50/150\n",
      "581/581 [==============================] - 0s 171us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 51/150\n",
      "581/581 [==============================] - 0s 176us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "581/581 [==============================] - 0s 214us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 53/150\n",
      "581/581 [==============================] - 0s 220us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 54/150\n",
      "581/581 [==============================] - 0s 186us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "581/581 [==============================] - 0s 198us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 56/150\n",
      "581/581 [==============================] - 0s 199us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "581/581 [==============================] - 0s 205us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 58/150\n",
      "581/581 [==============================] - 0s 196us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 59/150\n",
      "581/581 [==============================] - 0s 171us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "581/581 [==============================] - 0s 167us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 61/150\n",
      "581/581 [==============================] - 0s 192us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 62/150\n",
      "581/581 [==============================] - 0s 145us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 63/150\n",
      "581/581 [==============================] - 0s 208us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 64/150\n",
      "581/581 [==============================] - 0s 203us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 65/150\n",
      "581/581 [==============================] - 0s 199us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 66/150\n",
      "581/581 [==============================] - 0s 189us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 67/150\n",
      "581/581 [==============================] - 0s 175us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 68/150\n",
      "581/581 [==============================] - 0s 162us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "581/581 [==============================] - 0s 205us/step - loss: -2449.3943 - acc: 0.0000e+00 0s - loss: -2390.8458 - acc: 0.0000e+\n",
      "Epoch 70/150\n",
      "581/581 [==============================] - 0s 177us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 71/150\n",
      "581/581 [==============================] - 0s 147us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 72/150\n",
      "581/581 [==============================] - 0s 181us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 73/150\n",
      "581/581 [==============================] - 0s 170us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 0s 176us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 75/150\n",
      "581/581 [==============================] - 0s 170us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 76/150\n",
      "581/581 [==============================] - 0s 167us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 77/150\n",
      "581/581 [==============================] - 0s 167us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 78/150\n",
      "581/581 [==============================] - 0s 166us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 79/150\n",
      "581/581 [==============================] - 0s 136us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 80/150\n",
      "581/581 [==============================] - 0s 159us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "581/581 [==============================] - 0s 133us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 82/150\n",
      "581/581 [==============================] - 0s 134us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "581/581 [==============================] - 0s 162us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "581/581 [==============================] - 0s 135us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 85/150\n",
      "581/581 [==============================] - 0s 163us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "581/581 [==============================] - 0s 169us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 87/150\n",
      "581/581 [==============================] - 0s 189us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 88/150\n",
      "581/581 [==============================] - 0s 141us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 89/150\n",
      "581/581 [==============================] - 0s 290us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 90/150\n",
      "581/581 [==============================] - 0s 174us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 91/150\n",
      "581/581 [==============================] - 0s 158us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 92/150\n",
      "581/581 [==============================] - 0s 167us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 93/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "581/581 [==============================] - 0s 176us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "581/581 [==============================] - 0s 291us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 96/150\n",
      "581/581 [==============================] - 0s 165us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "581/581 [==============================] - 0s 172us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 98/150\n",
      "581/581 [==============================] - 0s 163us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "581/581 [==============================] - 0s 263us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 100/150\n",
      "581/581 [==============================] - 0s 214us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 101/150\n",
      "581/581 [==============================] - 0s 217us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "581/581 [==============================] - 0s 184us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 103/150\n",
      "581/581 [==============================] - 0s 257us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 104/150\n",
      "581/581 [==============================] - 0s 184us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 105/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 106/150\n",
      "581/581 [==============================] - 0s 182us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 107/150\n",
      "581/581 [==============================] - 0s 193us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 108/150\n",
      "581/581 [==============================] - 0s 142us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 109/150\n",
      "581/581 [==============================] - 0s 203us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 110/150\n",
      "581/581 [==============================] - 0s 168us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "581/581 [==============================] - 0s 206us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 112/150\n",
      "581/581 [==============================] - 0s 207us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 113/150\n",
      "581/581 [==============================] - 0s 199us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 114/150\n",
      "581/581 [==============================] - 0s 223us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 115/150\n",
      "581/581 [==============================] - 0s 172us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 116/150\n",
      "581/581 [==============================] - 0s 150us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 117/150\n",
      "581/581 [==============================] - 0s 211us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 118/150\n",
      "581/581 [==============================] - 0s 220us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "581/581 [==============================] - 0s 209us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "581/581 [==============================] - 0s 226us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 121/150\n",
      "581/581 [==============================] - 0s 182us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 122/150\n",
      "581/581 [==============================] - 0s 174us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 123/150\n",
      "581/581 [==============================] - 0s 198us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 124/150\n",
      "581/581 [==============================] - 0s 198us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 125/150\n",
      "581/581 [==============================] - 0s 212us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 127/150\n",
      "581/581 [==============================] - 0s 232us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 128/150\n",
      "581/581 [==============================] - 0s 196us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 129/150\n",
      "581/581 [==============================] - 0s 204us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 130/150\n",
      "581/581 [==============================] - 0s 236us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 131/150\n",
      "581/581 [==============================] - 0s 197us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 132/150\n",
      "581/581 [==============================] - 0s 216us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 133/150\n",
      "581/581 [==============================] - 0s 179us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "581/581 [==============================] - 0s 147us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 135/150\n",
      "581/581 [==============================] - 0s 144us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 136/150\n",
      "581/581 [==============================] - 0s 171us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 137/150\n",
      "581/581 [==============================] - 0s 159us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 138/150\n",
      "581/581 [==============================] - 0s 224us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 139/150\n",
      "581/581 [==============================] - 0s 265us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 140/150\n",
      "581/581 [==============================] - 0s 262us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 141/150\n",
      "581/581 [==============================] - 0s 249us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "581/581 [==============================] - 0s 301us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "581/581 [==============================] - 0s 361us/step - loss: -2449.3942 - acc: 0.0000e+00\n",
      "Epoch 144/150\n",
      "581/581 [==============================] - 0s 153us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 145/150\n",
      "581/581 [==============================] - 0s 226us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 146/150\n",
      "581/581 [==============================] - 0s 237us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 147/150\n",
      "581/581 [==============================] - 0s 231us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 148/150\n",
      "581/581 [==============================] - 0s 223us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 149/150\n",
      "581/581 [==============================] - 0s 238us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 0s 292us/step - loss: -2449.3943 - acc: 0.0000e+00\n",
      "581/581 [==============================] - 0s 117us/step\n",
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# load the dataset\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = X\n",
    "y = y\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd    pres\n",
       "0     59.746988  18.7  15.5  22.6   0.0   75.0  12.5  1023.9\n",
       "1     73.870523  18.6  13.9  23.4   0.0   45.0  10.1  1021.8\n",
       "2     59.394005  19.2  13.7  24.4   0.0   52.0   8.4  1021.5\n",
       "3     68.192323  20.6  15.7  26.8   0.0  135.0  10.1  1021.8\n",
       "4     78.645600  21.8  14.9  27.8   0.0  177.0  10.2  1020.0\n",
       "..          ...   ...   ...   ...   ...    ...   ...     ...\n",
       "772   40.983786   3.2   0.1   5.6   0.5   89.0  11.3  1019.5\n",
       "773   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6  1018.6\n",
       "774   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6  1026.4\n",
       "775   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8  1020.0\n",
       "776   37.605938   5.3   2.2   8.1   5.3  269.0  12.8  1023.6\n",
       "\n",
       "[581 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd    pres\n",
       "0     59.746988  18.7  15.5  22.6   0.0   75.0  12.5  1023.9\n",
       "1     73.870523  18.6  13.9  23.4   0.0   45.0  10.1  1021.8\n",
       "2     59.394005  19.2  13.7  24.4   0.0   52.0   8.4  1021.5\n",
       "3     68.192323  20.6  15.7  26.8   0.0  135.0  10.1  1021.8\n",
       "4     78.645600  21.8  14.9  27.8   0.0  177.0  10.2  1020.0\n",
       "..          ...   ...   ...   ...   ...    ...   ...     ...\n",
       "772   40.983786   3.2   0.1   5.6   0.5   89.0  11.3  1019.5\n",
       "773   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6  1018.6\n",
       "774   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6  1026.4\n",
       "775   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8  1020.0\n",
       "776   37.605938   5.3   2.2   8.1   5.3  269.0  12.8  1023.6\n",
       "\n",
       "[581 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd    pres\n",
       "0     59.746988  18.7  15.5  22.6   0.0   75.0  12.5  1023.9\n",
       "1     73.870523  18.6  13.9  23.4   0.0   45.0  10.1  1021.8\n",
       "2     59.394005  19.2  13.7  24.4   0.0   52.0   8.4  1021.5\n",
       "3     68.192323  20.6  15.7  26.8   0.0  135.0  10.1  1021.8\n",
       "4     78.645600  21.8  14.9  27.8   0.0  177.0  10.2  1020.0\n",
       "..          ...   ...   ...   ...   ...    ...   ...     ...\n",
       "772   40.983786   3.2   0.1   5.6   0.5   89.0  11.3  1019.5\n",
       "773   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6  1018.6\n",
       "774   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6  1026.4\n",
       "775   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8  1020.0\n",
       "776   37.605938   5.3   2.2   8.1   5.3  269.0  12.8  1023.6\n",
       "\n",
       "[581 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of training a final regression model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# generate regression dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "sc= MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.values.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=8, input_dim=8))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "regressor = KerasRegressor(build_fn=build_regressor, batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "406/406 [==============================] - 0s 535us/step - loss: 0.8122 - mean_absolute_error: 0.8745 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "406/406 [==============================] - 0s 103us/step - loss: 0.4445 - mean_absolute_error: 0.6311 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "406/406 [==============================] - 0s 202us/step - loss: 0.2196 - mean_absolute_error: 0.4172 - acc: 0.0025\n",
      "Epoch 4/100\n",
      "406/406 [==============================] - 0s 70us/step - loss: 0.1091 - mean_absolute_error: 0.2619 - acc: 0.0025\n",
      "Epoch 5/100\n",
      "406/406 [==============================] - 0s 96us/step - loss: 0.0667 - mean_absolute_error: 0.1891 - acc: 0.0025\n",
      "Epoch 6/100\n",
      "406/406 [==============================] - 0s 55us/step - loss: 0.0541 - mean_absolute_error: 0.1776 - acc: 0.0025\n",
      "Epoch 7/100\n",
      "406/406 [==============================] - 0s 76us/step - loss: 0.0511 - mean_absolute_error: 0.1796 - acc: 0.0025\n",
      "Epoch 8/100\n",
      "406/406 [==============================] - 0s 60us/step - loss: 0.0491 - mean_absolute_error: 0.1776 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "406/406 [==============================] - 0s 93us/step - loss: 0.0471 - mean_absolute_error: 0.1736 - acc: 0.0025\n",
      "Epoch 10/100\n",
      "406/406 [==============================] - 0s 98us/step - loss: 0.0452 - mean_absolute_error: 0.1696 - acc: 0.0025\n",
      "Epoch 11/100\n",
      "406/406 [==============================] - 0s 49us/step - loss: 0.0432 - mean_absolute_error: 0.1661 - acc: 0.0025\n",
      "Epoch 12/100\n",
      "406/406 [==============================] - 0s 41us/step - loss: 0.0414 - mean_absolute_error: 0.1622 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "406/406 [==============================] - 0s 41us/step - loss: 0.0396 - mean_absolute_error: 0.1584 - acc: 0.0025\n",
      "Epoch 14/100\n",
      "406/406 [==============================] - 0s 128us/step - loss: 0.0379 - mean_absolute_error: 0.1549 - acc: 0.0025\n",
      "Epoch 15/100\n",
      "406/406 [==============================] - 0s 210us/step - loss: 0.0363 - mean_absolute_error: 0.1519 - acc: 0.0025\n",
      "Epoch 16/100\n",
      "406/406 [==============================] - 0s 81us/step - loss: 0.0347 - mean_absolute_error: 0.1482 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "406/406 [==============================] - 0s 86us/step - loss: 0.0334 - mean_absolute_error: 0.1456 - acc: 0.0025\n",
      "Epoch 18/100\n",
      "406/406 [==============================] - 0s 96us/step - loss: 0.0318 - mean_absolute_error: 0.1421 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "406/406 [==============================] - 0s 65us/step - loss: 0.0305 - mean_absolute_error: 0.1390 - acc: 0.0025\n",
      "Epoch 20/100\n",
      "406/406 [==============================] - 0s 81us/step - loss: 0.0294 - mean_absolute_error: 0.1364 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "406/406 [==============================] - 0s 104us/step - loss: 0.0281 - mean_absolute_error: 0.1327 - acc: 0.0025\n",
      "Epoch 22/100\n",
      "406/406 [==============================] - 0s 80us/step - loss: 0.0271 - mean_absolute_error: 0.1295 - acc: 0.0025\n",
      "Epoch 23/100\n",
      "406/406 [==============================] - 0s 52us/step - loss: 0.0261 - mean_absolute_error: 0.1267 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "406/406 [==============================] - 0s 68us/step - loss: 0.0251 - mean_absolute_error: 0.1248 - acc: 0.0025\n",
      "Epoch 25/100\n",
      "406/406 [==============================] - 0s 91us/step - loss: 0.0242 - mean_absolute_error: 0.1223 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "406/406 [==============================] - 0s 75us/step - loss: 0.0233 - mean_absolute_error: 0.1194 - acc: 0.0025\n",
      "Epoch 27/100\n",
      "406/406 [==============================] - 0s 78us/step - loss: 0.0225 - mean_absolute_error: 0.1172 - acc: 0.0025\n",
      "Epoch 28/100\n",
      "406/406 [==============================] - 0s 71us/step - loss: 0.0218 - mean_absolute_error: 0.1149 - acc: 0.0025\n",
      "Epoch 29/100\n",
      "406/406 [==============================] - 0s 78us/step - loss: 0.0211 - mean_absolute_error: 0.1124 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "406/406 [==============================] - 0s 72us/step - loss: 0.0204 - mean_absolute_error: 0.1104 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "406/406 [==============================] - 0s 67us/step - loss: 0.0198 - mean_absolute_error: 0.1086 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "406/406 [==============================] - 0s 63us/step - loss: 0.0192 - mean_absolute_error: 0.1062 - acc: 0.0025\n",
      "Epoch 33/100\n",
      "406/406 [==============================] - 0s 80us/step - loss: 0.0187 - mean_absolute_error: 0.1041 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "406/406 [==============================] - 0s 72us/step - loss: 0.0182 - mean_absolute_error: 0.1025 - acc: 0.0025\n",
      "Epoch 35/100\n",
      "406/406 [==============================] - 0s 79us/step - loss: 0.0177 - mean_absolute_error: 0.1011 - acc: 0.0025\n",
      "Epoch 36/100\n",
      "406/406 [==============================] - 0s 94us/step - loss: 0.0172 - mean_absolute_error: 0.0990 - acc: 0.0025\n",
      "Epoch 37/100\n",
      "406/406 [==============================] - 0s 86us/step - loss: 0.0168 - mean_absolute_error: 0.0975 - acc: 0.0025\n",
      "Epoch 38/100\n",
      "406/406 [==============================] - 0s 122us/step - loss: 0.0164 - mean_absolute_error: 0.0957 - acc: 0.0025\n",
      "Epoch 39/100\n",
      "406/406 [==============================] - 0s 85us/step - loss: 0.0160 - mean_absolute_error: 0.0945 - acc: 0.0025\n",
      "Epoch 40/100\n",
      "406/406 [==============================] - 0s 103us/step - loss: 0.0157 - mean_absolute_error: 0.0933 - acc: 0.0025\n",
      "Epoch 41/100\n",
      "406/406 [==============================] - 0s 79us/step - loss: 0.0154 - mean_absolute_error: 0.0918 - acc: 0.0025\n",
      "Epoch 42/100\n",
      "406/406 [==============================] - 0s 60us/step - loss: 0.0150 - mean_absolute_error: 0.0906 - acc: 0.0025\n",
      "Epoch 43/100\n",
      "406/406 [==============================] - 0s 62us/step - loss: 0.0147 - mean_absolute_error: 0.0894 - acc: 0.0025\n",
      "Epoch 44/100\n",
      "406/406 [==============================] - 0s 51us/step - loss: 0.0145 - mean_absolute_error: 0.0888 - acc: 0.0025\n",
      "Epoch 45/100\n",
      "406/406 [==============================] - 0s 45us/step - loss: 0.0142 - mean_absolute_error: 0.0869 - acc: 0.0025\n",
      "Epoch 46/100\n",
      "406/406 [==============================] - 0s 67us/step - loss: 0.0139 - mean_absolute_error: 0.0856 - acc: 0.0025\n",
      "Epoch 47/100\n",
      "406/406 [==============================] - 0s 51us/step - loss: 0.0137 - mean_absolute_error: 0.0849 - acc: 0.0025\n",
      "Epoch 48/100\n",
      "406/406 [==============================] - 0s 72us/step - loss: 0.0135 - mean_absolute_error: 0.0842 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "406/406 [==============================] - 0s 56us/step - loss: 0.0133 - mean_absolute_error: 0.0831 - acc: 0.0025\n",
      "Epoch 50/100\n",
      "406/406 [==============================] - 0s 59us/step - loss: 0.0131 - mean_absolute_error: 0.0823 - acc: 0.0025\n",
      "Epoch 51/100\n",
      "406/406 [==============================] - 0s 56us/step - loss: 0.0129 - mean_absolute_error: 0.0821 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "406/406 [==============================] - 0s 70us/step - loss: 0.0127 - mean_absolute_error: 0.0804 - acc: 0.0025\n",
      "Epoch 53/100\n",
      "406/406 [==============================] - 0s 53us/step - loss: 0.0125 - mean_absolute_error: 0.0792 - acc: 0.0025\n",
      "Epoch 54/100\n",
      "406/406 [==============================] - 0s 53us/step - loss: 0.0124 - mean_absolute_error: 0.0790 - acc: 0.0025\n",
      "Epoch 55/100\n",
      "406/406 [==============================] - 0s 86us/step - loss: 0.0122 - mean_absolute_error: 0.0784 - acc: 0.0025\n",
      "Epoch 56/100\n",
      "406/406 [==============================] - 0s 75us/step - loss: 0.0120 - mean_absolute_error: 0.0777 - acc: 0.0025\n",
      "Epoch 57/100\n",
      "406/406 [==============================] - 0s 125us/step - loss: 0.0119 - mean_absolute_error: 0.0767 - acc: 0.0025\n",
      "Epoch 58/100\n",
      "406/406 [==============================] - 0s 71us/step - loss: 0.0118 - mean_absolute_error: 0.0760 - acc: 0.0025\n",
      "Epoch 59/100\n",
      "406/406 [==============================] - 0s 70us/step - loss: 0.0117 - mean_absolute_error: 0.0754 - acc: 0.0025\n",
      "Epoch 60/100\n",
      "406/406 [==============================] - 0s 37us/step - loss: 0.0115 - mean_absolute_error: 0.0750 - acc: 0.0025\n",
      "Epoch 61/100\n",
      "406/406 [==============================] - 0s 71us/step - loss: 0.0114 - mean_absolute_error: 0.0745 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "406/406 [==============================] - 0s 55us/step - loss: 0.0114 - mean_absolute_error: 0.0737 - acc: 0.0025\n",
      "Epoch 63/100\n",
      "406/406 [==============================] - 0s 49us/step - loss: 0.0113 - mean_absolute_error: 0.0736 - acc: 0.0025\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406/406 [==============================] - 0s 61us/step - loss: 0.0112 - mean_absolute_error: 0.0730 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "406/406 [==============================] - 0s 48us/step - loss: 0.0110 - mean_absolute_error: 0.0724 - acc: 0.0025\n",
      "Epoch 66/100\n",
      "406/406 [==============================] - 0s 61us/step - loss: 0.0110 - mean_absolute_error: 0.0724 - acc: 0.0025\n",
      "Epoch 67/100\n",
      "406/406 [==============================] - 0s 55us/step - loss: 0.0109 - mean_absolute_error: 0.0713 - acc: 0.0025\n",
      "Epoch 68/100\n",
      "406/406 [==============================] - 0s 63us/step - loss: 0.0108 - mean_absolute_error: 0.0713 - acc: 0.0025\n",
      "Epoch 69/100\n",
      "406/406 [==============================] - 0s 64us/step - loss: 0.0107 - mean_absolute_error: 0.0712 - acc: 0.0025\n",
      "Epoch 70/100\n",
      "406/406 [==============================] - 0s 61us/step - loss: 0.0107 - mean_absolute_error: 0.0707 - acc: 0.0025\n",
      "Epoch 71/100\n",
      "406/406 [==============================] - 0s 62us/step - loss: 0.0106 - mean_absolute_error: 0.0704 - acc: 0.0025\n",
      "Epoch 72/100\n",
      "406/406 [==============================] - 0s 79us/step - loss: 0.0106 - mean_absolute_error: 0.0705 - acc: 0.0025\n",
      "Epoch 73/100\n",
      "406/406 [==============================] - 0s 53us/step - loss: 0.0105 - mean_absolute_error: 0.0700 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "406/406 [==============================] - 0s 59us/step - loss: 0.0105 - mean_absolute_error: 0.0693 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "406/406 [==============================] - 0s 47us/step - loss: 0.0104 - mean_absolute_error: 0.0693 - acc: 0.0025\n",
      "Epoch 76/100\n",
      "406/406 [==============================] - 0s 61us/step - loss: 0.0103 - mean_absolute_error: 0.0693 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "406/406 [==============================] - 0s 54us/step - loss: 0.0103 - mean_absolute_error: 0.0692 - acc: 0.0025\n",
      "Epoch 78/100\n",
      "406/406 [==============================] - 0s 74us/step - loss: 0.0103 - mean_absolute_error: 0.0695 - acc: 0.0025\n",
      "Epoch 79/100\n",
      "406/406 [==============================] - 0s 66us/step - loss: 0.0103 - mean_absolute_error: 0.0684 - acc: 0.0025\n",
      "Epoch 80/100\n",
      "406/406 [==============================] - 0s 90us/step - loss: 0.0103 - mean_absolute_error: 0.0698 - acc: 0.0025\n",
      "Epoch 81/100\n",
      "406/406 [==============================] - 0s 68us/step - loss: 0.0101 - mean_absolute_error: 0.0686 - acc: 0.0025\n",
      "Epoch 82/100\n",
      "406/406 [==============================] - 0s 64us/step - loss: 0.0101 - mean_absolute_error: 0.0678 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "406/406 [==============================] - 0s 58us/step - loss: 0.0101 - mean_absolute_error: 0.0681 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "406/406 [==============================] - 0s 52us/step - loss: 0.0101 - mean_absolute_error: 0.0682 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "406/406 [==============================] - 0s 46us/step - loss: 0.0100 - mean_absolute_error: 0.0677 - acc: 0.0025\n",
      "Epoch 86/100\n",
      "406/406 [==============================] - 0s 51us/step - loss: 0.0100 - mean_absolute_error: 0.0684 - acc: 0.0025\n",
      "Epoch 87/100\n",
      "406/406 [==============================] - 0s 52us/step - loss: 0.0100 - mean_absolute_error: 0.0673 - acc: 0.0025\n",
      "Epoch 88/100\n",
      "406/406 [==============================] - 0s 64us/step - loss: 0.0099 - mean_absolute_error: 0.0679 - acc: 0.0025\n",
      "Epoch 89/100\n",
      "406/406 [==============================] - 0s 52us/step - loss: 0.0099 - mean_absolute_error: 0.0678 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "406/406 [==============================] - 0s 53us/step - loss: 0.0098 - mean_absolute_error: 0.0671 - acc: 0.0025\n",
      "Epoch 91/100\n",
      "406/406 [==============================] - 0s 64us/step - loss: 0.0098 - mean_absolute_error: 0.0667 - acc: 0.0025\n",
      "Epoch 92/100\n",
      "406/406 [==============================] - 0s 50us/step - loss: 0.0098 - mean_absolute_error: 0.0675 - acc: 0.0025\n",
      "Epoch 93/100\n",
      "406/406 [==============================] - 0s 48us/step - loss: 0.0098 - mean_absolute_error: 0.0670 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "406/406 [==============================] - 0s 59us/step - loss: 0.0098 - mean_absolute_error: 0.0664 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "406/406 [==============================] - 0s 53us/step - loss: 0.0097 - mean_absolute_error: 0.0672 - acc: 0.0025\n",
      "Epoch 96/100\n",
      "406/406 [==============================] - 0s 54us/step - loss: 0.0097 - mean_absolute_error: 0.0672 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "406/406 [==============================] - 0s 54us/step - loss: 0.0097 - mean_absolute_error: 0.0667 - acc: 0.0025\n",
      "Epoch 98/100\n",
      "406/406 [==============================] - 0s 42us/step - loss: 0.0097 - mean_absolute_error: 0.0662 - acc: 0.0025\n",
      "Epoch 99/100\n",
      "406/406 [==============================] - 0s 60us/step - loss: 0.0097 - mean_absolute_error: 0.0667 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "406/406 [==============================] - 0s 51us/step - loss: 0.0096 - mean_absolute_error: 0.0666 - acc: 0.0025\n"
     ]
    }
   ],
   "source": [
    "results=regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.117\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.117\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred, y_test))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hridoy/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2658291e-03],\n",
       "       [ 2.9294868e-04],\n",
       "       [ 1.7781124e-03],\n",
       "       [ 2.7008448e-03],\n",
       "       [ 1.2501993e-03],\n",
       "       [-1.3244732e-03],\n",
       "       [ 4.8760585e-03],\n",
       "       [ 1.0128574e-03],\n",
       "       [ 8.5311476e-06],\n",
       "       [ 2.5943320e-03],\n",
       "       [-1.6499662e-03],\n",
       "       [ 3.7841566e-03],\n",
       "       [-2.3581547e-04],\n",
       "       [ 1.2830445e-03],\n",
       "       [ 4.4978235e-04],\n",
       "       [ 1.6589141e-03],\n",
       "       [-8.7097811e-05],\n",
       "       [ 3.9160624e-03],\n",
       "       [ 3.2433006e-03],\n",
       "       [ 4.5861240e-04],\n",
       "       [ 2.1932204e-03],\n",
       "       [ 1.8585848e-03],\n",
       "       [ 3.8763753e-03],\n",
       "       [ 2.8671799e-03],\n",
       "       [-2.3095077e-04],\n",
       "       [ 2.4831546e-03],\n",
       "       [ 4.5389570e-03],\n",
       "       [ 2.0181295e-03],\n",
       "       [ 1.4877302e-03],\n",
       "       [ 1.0236857e-03],\n",
       "       [ 2.2821864e-03],\n",
       "       [ 2.6716909e-04],\n",
       "       [ 3.7885942e-03],\n",
       "       [-6.0284539e-04],\n",
       "       [ 1.2437114e-03],\n",
       "       [-8.9490728e-05],\n",
       "       [-3.0357740e-04],\n",
       "       [ 1.2071213e-03],\n",
       "       [ 4.7295250e-04],\n",
       "       [ 1.3401266e-03],\n",
       "       [ 1.3377715e-03],\n",
       "       [ 1.7442637e-03],\n",
       "       [ 7.7334233e-05],\n",
       "       [ 1.4335109e-03],\n",
       "       [ 3.5452009e-03],\n",
       "       [-1.8531652e-03],\n",
       "       [ 2.2859662e-05],\n",
       "       [ 3.4871404e-03],\n",
       "       [ 1.6583919e-03],\n",
       "       [ 4.0235906e-03],\n",
       "       [ 3.5112980e-03],\n",
       "       [-6.3419226e-05],\n",
       "       [ 4.7360440e-03],\n",
       "       [-1.4370701e-03],\n",
       "       [ 1.1230120e-03],\n",
       "       [ 4.1804565e-03],\n",
       "       [ 3.6588695e-03],\n",
       "       [ 4.9749436e-03],\n",
       "       [ 3.9587254e-03],\n",
       "       [ 3.1668684e-03],\n",
       "       [ 6.6481082e-04],\n",
       "       [ 2.7953396e-03],\n",
       "       [-4.5756903e-04],\n",
       "       [ 1.5335053e-04],\n",
       "       [-3.6185578e-04],\n",
       "       [ 1.7529665e-03],\n",
       "       [ 6.7636732e-04],\n",
       "       [ 1.5476934e-03],\n",
       "       [ 3.7083842e-03],\n",
       "       [-1.2522491e-03],\n",
       "       [ 3.3094680e-03],\n",
       "       [ 4.0095653e-03],\n",
       "       [-6.4155203e-05],\n",
       "       [ 6.1723730e-04],\n",
       "       [ 3.7441724e-03],\n",
       "       [-1.4128791e-03],\n",
       "       [ 1.4073141e-03],\n",
       "       [ 5.0476762e-03],\n",
       "       [-7.3186221e-04],\n",
       "       [ 2.1122294e-03],\n",
       "       [ 1.7602368e-03],\n",
       "       [-1.5041702e-03],\n",
       "       [ 1.0378570e-03],\n",
       "       [ 2.7466209e-03],\n",
       "       [ 1.8198240e-03],\n",
       "       [ 4.3440131e-03],\n",
       "       [ 2.0201276e-03],\n",
       "       [-3.4429738e-04],\n",
       "       [ 4.0931832e-03],\n",
       "       [ 9.0498314e-04],\n",
       "       [-3.0903076e-04],\n",
       "       [ 3.7033595e-03],\n",
       "       [ 2.9323671e-03],\n",
       "       [ 3.8845143e-03],\n",
       "       [-1.2075141e-03],\n",
       "       [ 3.0594612e-03],\n",
       "       [ 3.8867644e-03],\n",
       "       [ 1.9991167e-03],\n",
       "       [-1.1721769e-03],\n",
       "       [ 1.0829269e-03],\n",
       "       [ 1.3962875e-03],\n",
       "       [ 4.0615508e-03],\n",
       "       [ 3.1168722e-03],\n",
       "       [ 1.6698486e-04],\n",
       "       [ 1.9365177e-03],\n",
       "       [ 3.0723682e-03],\n",
       "       [ 2.8933180e-03],\n",
       "       [ 1.0881090e-03],\n",
       "       [ 9.1125199e-04],\n",
       "       [ 3.9234594e-04],\n",
       "       [ 3.3976841e-03],\n",
       "       [ 3.9938511e-04],\n",
       "       [ 3.8810296e-04],\n",
       "       [ 1.8635718e-03],\n",
       "       [ 2.5624968e-04],\n",
       "       [-2.1127951e-03],\n",
       "       [ 4.8086443e-03],\n",
       "       [ 3.8109934e-03],\n",
       "       [-8.5854204e-05],\n",
       "       [-1.0964097e-03],\n",
       "       [-4.3608909e-04],\n",
       "       [-4.2603947e-03],\n",
       "       [ 2.5411914e-03],\n",
       "       [ 7.9504680e-04],\n",
       "       [ 2.9293925e-04],\n",
       "       [ 2.0296499e-03],\n",
       "       [ 4.0126555e-03],\n",
       "       [ 5.6756544e-05],\n",
       "       [-1.2019149e-03],\n",
       "       [-1.6566303e-03],\n",
       "       [ 8.7156019e-05],\n",
       "       [ 3.5579992e-03],\n",
       "       [ 2.5627161e-03],\n",
       "       [-1.1314683e-03],\n",
       "       [ 1.6818715e-03],\n",
       "       [ 3.7090974e-03],\n",
       "       [ 3.1232729e-03],\n",
       "       [ 3.1635063e-03],\n",
       "       [ 2.5940810e-03],\n",
       "       [ 3.8959158e-03],\n",
       "       [-8.6589623e-04],\n",
       "       [-3.9600837e-04],\n",
       "       [-2.0442549e-03],\n",
       "       [ 3.1557065e-03],\n",
       "       [ 2.8999727e-03],\n",
       "       [ 1.7225605e-03],\n",
       "       [ 1.5149204e-03],\n",
       "       [ 1.0415434e-03],\n",
       "       [ 3.8932301e-03],\n",
       "       [ 1.6675108e-03],\n",
       "       [ 1.0493156e-03],\n",
       "       [-1.2031570e-03],\n",
       "       [ 8.4462774e-04],\n",
       "       [-6.1721075e-04],\n",
       "       [-7.3873170e-04],\n",
       "       [-1.7854407e-03],\n",
       "       [ 3.4091885e-03],\n",
       "       [ 3.9031138e-03],\n",
       "       [ 8.5817726e-04],\n",
       "       [ 1.5281040e-03],\n",
       "       [ 2.0904841e-03],\n",
       "       [ 1.5640472e-03],\n",
       "       [ 3.2093781e-03],\n",
       "       [ 2.1456107e-03],\n",
       "       [ 7.7697518e-04],\n",
       "       [ 1.9790232e-03],\n",
       "       [-1.4575559e-03],\n",
       "       [ 2.3766854e-03],\n",
       "       [ 1.6971142e-03],\n",
       "       [ 3.7205741e-03],\n",
       "       [ 5.3811679e-03],\n",
       "       [ 1.8033850e-03],\n",
       "       [-4.0510553e-05],\n",
       "       [ 1.3088608e-03],\n",
       "       [ 2.7814291e-03]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test ,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3444722527141212"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
