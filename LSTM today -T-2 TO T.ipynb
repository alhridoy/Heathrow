{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's first load the data and take a look at what we have.\n",
    "df = pd.read_csv('heathrow_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'], \n",
    "               axis=1,\n",
    "              inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>Hum</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.12</td>\n",
       "      <td>59.75</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>58.67</td>\n",
       "      <td>21.35</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.395833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.04</td>\n",
       "      <td>73.87</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.83</td>\n",
       "      <td>25.76</td>\n",
       "      <td>34.37</td>\n",
       "      <td>14.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194.00</td>\n",
       "      <td>59.39</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>65.33</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36.05</td>\n",
       "      <td>20.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.27</td>\n",
       "      <td>68.19</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.00</td>\n",
       "      <td>16.71</td>\n",
       "      <td>42.57</td>\n",
       "      <td>22.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.16</td>\n",
       "      <td>78.65</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>59.58</td>\n",
       "      <td>26.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>17.279167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>85.24</td>\n",
       "      <td>40.98</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>84.79</td>\n",
       "      <td>10.20</td>\n",
       "      <td>25.35</td>\n",
       "      <td>7.420833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>163.94</td>\n",
       "      <td>37.20</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>91.63</td>\n",
       "      <td>6.15</td>\n",
       "      <td>27.77</td>\n",
       "      <td>15.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>282.06</td>\n",
       "      <td>58.82</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "      <td>94.25</td>\n",
       "      <td>17.17</td>\n",
       "      <td>32.50</td>\n",
       "      <td>13.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>147.20</td>\n",
       "      <td>37.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>86.63</td>\n",
       "      <td>8.21</td>\n",
       "      <td>25.78</td>\n",
       "      <td>6.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>74.63</td>\n",
       "      <td>37.61</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "      <td>78.79</td>\n",
       "      <td>8.37</td>\n",
       "      <td>25.99</td>\n",
       "      <td>9.929167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp  wdir  wspd    pres    Hum  \\\n",
       "0       232.12       59.75  18.7  15.5  22.6   0.0     2  12.5  1023.9  58.67   \n",
       "1       168.04       73.87  18.6  13.9  23.4   0.0     1  10.1  1021.8  65.83   \n",
       "2       194.00       59.39  19.2  13.7  24.4   0.0     2   8.4  1021.5  65.33   \n",
       "3       343.27       68.19  20.6  15.7  26.8   0.0     2  10.1  1021.8  65.00   \n",
       "4       190.16       78.65  21.8  14.9  27.8   0.0     3  10.2  1020.0  59.58   \n",
       "..         ...         ...   ...   ...   ...   ...   ...   ...     ...    ...   \n",
       "576      85.24       40.98   3.2   0.1   5.6   0.5     2  11.3  1019.5  84.79   \n",
       "577     163.94       37.20  -0.1  -1.7   2.1   0.0     4  10.6  1018.6  91.63   \n",
       "578     282.06       58.82   0.1  -2.1   2.6   0.0     3   6.6  1026.4  94.25   \n",
       "579     147.20       37.50   4.8  -0.8   8.3   0.5     3  14.8  1020.0  86.63   \n",
       "580      74.63       37.61   5.3   2.2   8.1   5.3     4  12.8  1023.6  78.79   \n",
       "\n",
       "        NO    NO2       PM10  \n",
       "0    21.35  27.00  12.395833  \n",
       "1    25.76  34.37  14.937500  \n",
       "2    15.23  36.05  20.891667  \n",
       "3    16.71  42.57  22.316667  \n",
       "4    26.03  38.74  17.279167  \n",
       "..     ...    ...        ...  \n",
       "576  10.20  25.35   7.420833  \n",
       "577   6.15  27.77  15.304167  \n",
       "578  17.17  32.50  13.537500  \n",
       "579   8.21  25.78   6.412500  \n",
       "580   8.37  25.99   9.929167  \n",
       "\n",
       "[578 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Nox_tropo'], axis=1).values\n",
    "y = df['Nox_tropo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 2, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12]], axis=1, inplace=True)\n",
    "# print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var1(t-2)', 'var2(t-2)', 'var3(t-2)', 'var4(t-2)', 'var5(t-2)',\n",
       "       'var6(t-2)', 'var7(t-2)', 'var8(t-2)', 'var9(t-2)', 'var10(t-2)',\n",
       "       'var11(t-2)', 'var12(t-2)', 'var13(t-2)', 'var1(t-1)', 'var2(t-1)',\n",
       "       'var3(t-1)', 'var4(t-1)', 'var5(t-1)', 'var6(t-1)', 'var7(t-1)',\n",
       "       'var8(t-1)', 'var9(t-1)', 'var10(t-1)', 'var11(t-1)', 'var12(t-1)',\n",
       "       'var13(t-1)', 'var1(t)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reframed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 1, 26) (460,) (116, 1, 26) (116,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "#80% training data\n",
    "n_train_hours = 460\n",
    "train = values[:n_train_hours]\n",
    "test = values[n_train_hours:]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# train = data.values[:459]\n",
    "# test = data.values[459:]\n",
    "\n",
    "# # Separate input and output\n",
    "# train_X, train_y = train[:, :-1], train[:, -1]\n",
    "# test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# # Reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# # Print all shapes\n",
    "# train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = reframed.values\n",
    "# #values = scaled\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled_features = scaler.fit_transform(values[:,:-1])\n",
    "# scaled_label = scaler.fit_transform(values[:,-1].reshape(-1,1))\n",
    "# values = np.column_stack((scaled_features, scaled_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape[0], train_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 - 2s - loss: 0.0698 - val_loss: 0.0076\n",
      "Epoch 2/20\n",
      "23/23 - 0s - loss: 0.0188 - val_loss: 0.0102\n",
      "Epoch 3/20\n",
      "23/23 - 0s - loss: 0.0149 - val_loss: 0.0073\n",
      "Epoch 4/20\n",
      "23/23 - 0s - loss: 0.0148 - val_loss: 0.0076\n",
      "Epoch 5/20\n",
      "23/23 - 0s - loss: 0.0143 - val_loss: 0.0072\n",
      "Epoch 6/20\n",
      "23/23 - 0s - loss: 0.0140 - val_loss: 0.0070\n",
      "Epoch 7/20\n",
      "23/23 - 0s - loss: 0.0139 - val_loss: 0.0069\n",
      "Epoch 8/20\n",
      "23/23 - 0s - loss: 0.0137 - val_loss: 0.0068\n",
      "Epoch 9/20\n",
      "23/23 - 0s - loss: 0.0136 - val_loss: 0.0068\n",
      "Epoch 10/20\n",
      "23/23 - 0s - loss: 0.0135 - val_loss: 0.0068\n",
      "Epoch 11/20\n",
      "23/23 - 0s - loss: 0.0134 - val_loss: 0.0068\n",
      "Epoch 12/20\n",
      "23/23 - 0s - loss: 0.0133 - val_loss: 0.0068\n",
      "Epoch 13/20\n",
      "23/23 - 0s - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 14/20\n",
      "23/23 - 0s - loss: 0.0131 - val_loss: 0.0069\n",
      "Epoch 15/20\n",
      "23/23 - 0s - loss: 0.0131 - val_loss: 0.0069\n",
      "Epoch 16/20\n",
      "23/23 - 0s - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 17/20\n",
      "23/23 - 0s - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 18/20\n",
      "23/23 - 0s - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 19/20\n",
      "23/23 - 0s - loss: 0.0128 - val_loss: 0.0070\n",
      "Epoch 20/20\n",
      "23/23 - 0s - loss: 0.0128 - val_loss: 0.0071\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model = Sequential()\n",
    "model.add(LSTM(13, input_shape=(train_X.shape[1], train_X.shape[2]),activation='relu'))\n",
    "model.add(Dense(38, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=20, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (116,26) (13,) (116,26) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-999640c0408f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# invert scaling for forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# invert scaling for actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (116,26) (13,) (116,26) "
     ]
    }
   ],
   "source": [
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test RMSE: 63.508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 61-1 Test RMSE: Test RMSE: 63.163\n",
    "\n",
    "13-40-1 Test RMSE: 67.366\n",
    "\n",
    "13-100-1 Test RMSE: 65.965\n",
    "\n",
    "13- -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
