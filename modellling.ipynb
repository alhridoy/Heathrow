{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's first load the data and take a look at what we have.\n",
    "df = pd.read_csv('Heathrow_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/7/18</td>\n",
       "      <td>232.1240</td>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/7/18</td>\n",
       "      <td>168.0445</td>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/7/18</td>\n",
       "      <td>194.0030</td>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/7/18</td>\n",
       "      <td>343.2730</td>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/7/18</td>\n",
       "      <td>190.1570</td>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>6/1/21</td>\n",
       "      <td>85.2440</td>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>7/1/21</td>\n",
       "      <td>163.9400</td>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>9/1/21</td>\n",
       "      <td>282.0585</td>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>16/1/21</td>\n",
       "      <td>147.2020</td>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>17/1/21</td>\n",
       "      <td>74.6270</td>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd  \\\n",
       "0    10/7/18   232.1240   59.746988  18.7  15.5  22.6   0.0   75.0  12.5   \n",
       "1    11/7/18   168.0445   73.870523  18.6  13.9  23.4   0.0   45.0  10.1   \n",
       "2    12/7/18   194.0030   59.394005  19.2  13.7  24.4   0.0   52.0   8.4   \n",
       "3    13/7/18   343.2730   68.192323  20.6  15.7  26.8   0.0  135.0  10.1   \n",
       "4    14/7/18   190.1570   78.645600  21.8  14.9  27.8   0.0  177.0  10.2   \n",
       "..       ...        ...         ...   ...   ...   ...   ...    ...   ...   \n",
       "772   6/1/21    85.2440   40.983786   3.2   0.1   5.6   0.5   89.0  11.3   \n",
       "773   7/1/21   163.9400   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6   \n",
       "774   9/1/21   282.0585   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6   \n",
       "775  16/1/21   147.2020   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8   \n",
       "776  17/1/21    74.6270   37.605938   5.3   2.2   8.1   5.3  269.0  12.8   \n",
       "\n",
       "       pres  \n",
       "0    1023.9  \n",
       "1    1021.8  \n",
       "2    1021.5  \n",
       "3    1021.8  \n",
       "4    1020.0  \n",
       "..      ...  \n",
       "772  1019.5  \n",
       "773  1018.6  \n",
       "774  1026.4  \n",
       "775  1020.0  \n",
       "776  1023.6  \n",
       "\n",
       "[581 rows x 10 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'], \n",
    "               axis=1,\n",
    "              inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Nox_tropo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Nox_tropo'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to 70% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first five rows after standardisation look like this:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "#DataFlair\n",
    "standard_scaler.fit(X_train)\n",
    "X_train_standard = standard_scaler.transform(X_train)\n",
    "X_test_standard = standard_scaler.transform(X_test)\n",
    "print('The first five rows after standardisation look like this:\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our SVM model on the training data is 0.11 out of 1\n",
      "Accuracy of our SVM model on the test data is 0.03 out of 1\n"
     ]
    }
   ],
   "source": [
    "#DataFlair\n",
    "SVM = SVR(kernel='rbf', gamma=.10, C=1.0)\n",
    "SVM.fit(X_train_standard, y_train)\n",
    "print('Accuracy of our SVM model on the training data is {:.2f} out of 1'.format(SVM.score(X_train_standard, y_train)))\n",
    "print('Accuracy of our SVM model on the test data is {:.2f} out of 1'.format(SVM.score(X_test_standard, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVR()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict( X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 91.501\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_pred, y_test))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test ,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.21136658258776"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR MAE : 61.21136658258776\n",
    "    RMSE: Test RMSE: 91.501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Create MLPRegressor object\n",
    "mlp = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor()"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2600315750179685"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Score the model\n",
    "neural_network_regression_score = mlp.score(X_test, y_test)\n",
    "neural_network_regression_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "nnr_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 76.84\n",
      "Mean absolute error: 51.59\n",
      "R-squared: 0.26\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print(\"Root mean squared error: %.2f\"\n",
    "      % sqrt(mean_squared_error(y_test, nnr_pred)))\n",
    "# The absolute squared error\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, nnr_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R-squared: %.2f' % r2_score(y_test, nnr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.09800106392567"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, nnr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23444692080146678"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Score the model\n",
    "lasso_score = lasso.score(X_test, y_test)\n",
    "lasso_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "lasso_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 78.15\n",
      "Mean absolute error: 52.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Root mean squared error: %.2f\"\n",
    "      % sqrt(mean_squared_error(y_test, lasso_pred)))\n",
    "\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, lasso_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Create Random Forrest Regressor object\n",
    "regr_rf = RandomForestRegressor(n_estimators=200, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=1234)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model using the training sets\n",
    "regr_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23527210946963584"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the model\n",
    "decision_forest_score = regr_rf.score(X_test, y_test)\n",
    "decision_forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions using the testing set\n",
    "regr_rf_pred = regr_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 78.11\n",
      "Mean absolute error: 53.41\n",
      "R-squared: 0.24\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print(\"Root mean squared error: %.2f\"\n",
    "      % sqrt(mean_squared_error(y_test, regr_rf_pred)))\n",
    "# The absolute squared error\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, regr_rf_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R-squared: %.2f' % r2_score(y_test, regr_rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Create Decision Tree Regressor object\n",
    "tree_1 = DecisionTreeRegressor()\n",
    "\n",
    "tree_2 = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators=200, learning_rate=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.1,\n",
       "                  n_estimators=200)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model using the training sets\n",
    "tree_1.fit(X_train, y_train)\n",
    "tree_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2426883932895879"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Score the boosted decision tree model\n",
    "boosted_tree_score = tree_2.score(X_test, y_test)\n",
    "boosted_tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions using the testing set\n",
    "tree_1_pred = tree_1.predict(X_test)\n",
    "tree_2_pred = tree_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 77.73\n",
      "Mean absolute error: 51.20\n",
      "R-squared: 0.24\n"
     ]
    }
   ],
   "source": [
    "# # The coefficients\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Root mean squared error: %.2f\"\n",
    "      % sqrt(mean_squared_error(y_test, tree_2_pred)))\n",
    "# The absolute squared error\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(y_test, tree_2_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R-squared: %.2f' % r2_score(y_test, tree_2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.1240</td>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0445</td>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194.0030</td>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.2730</td>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.1570</td>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>85.2440</td>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>163.9400</td>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>282.0585</td>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>147.2020</td>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>74.6270</td>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd    pres\n",
       "0     232.1240   59.746988  18.7  15.5  22.6   0.0   75.0  12.5  1023.9\n",
       "1     168.0445   73.870523  18.6  13.9  23.4   0.0   45.0  10.1  1021.8\n",
       "2     194.0030   59.394005  19.2  13.7  24.4   0.0   52.0   8.4  1021.5\n",
       "3     343.2730   68.192323  20.6  15.7  26.8   0.0  135.0  10.1  1021.8\n",
       "4     190.1570   78.645600  21.8  14.9  27.8   0.0  177.0  10.2  1020.0\n",
       "..         ...         ...   ...   ...   ...   ...    ...   ...     ...\n",
       "772    85.2440   40.983786   3.2   0.1   5.6   0.5   89.0  11.3  1019.5\n",
       "773   163.9400   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6  1018.6\n",
       "774   282.0585   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6  1026.4\n",
       "775   147.2020   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8  1020.0\n",
       "776    74.6270   37.605938   5.3   2.2   8.1   5.3  269.0  12.8  1023.6\n",
       "\n",
       "[581 rows x 9 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.32124000e+02, 5.97469878e+01, 1.87000000e+01, ...,\n",
       "        7.50000000e+01, 1.25000000e+01, 1.02390000e+03],\n",
       "       [1.68044500e+02, 7.38705230e+01, 1.86000000e+01, ...,\n",
       "        4.50000000e+01, 1.01000000e+01, 1.02180000e+03],\n",
       "       [1.94003000e+02, 5.93940048e+01, 1.92000000e+01, ...,\n",
       "        5.20000000e+01, 8.40000000e+00, 1.02150000e+03],\n",
       "       ...,\n",
       "       [2.82058500e+02, 5.88182587e+01, 1.00000000e-01, ...,\n",
       "        1.78000000e+02, 6.60000000e+00, 1.02640000e+03],\n",
       "       [1.47202000e+02, 3.74967921e+01, 4.80000000e+00, ...,\n",
       "        2.14000000e+02, 1.48000000e+01, 1.02000000e+03],\n",
       "       [7.46270000e+01, 3.76059383e+01, 5.30000000e+00, ...,\n",
       "        2.69000000e+02, 1.28000000e+01, 1.02360000e+03]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.1240</td>\n",
       "      <td>59.746988</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0445</td>\n",
       "      <td>73.870523</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194.0030</td>\n",
       "      <td>59.394005</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.2730</td>\n",
       "      <td>68.192323</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.1570</td>\n",
       "      <td>78.645600</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>85.2440</td>\n",
       "      <td>40.983786</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>163.9400</td>\n",
       "      <td>37.200143</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>282.0585</td>\n",
       "      <td>58.818259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>147.2020</td>\n",
       "      <td>37.496792</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>74.6270</td>\n",
       "      <td>37.605938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp   wdir  wspd    pres\n",
       "0     232.1240   59.746988  18.7  15.5  22.6   0.0   75.0  12.5  1023.9\n",
       "1     168.0445   73.870523  18.6  13.9  23.4   0.0   45.0  10.1  1021.8\n",
       "2     194.0030   59.394005  19.2  13.7  24.4   0.0   52.0   8.4  1021.5\n",
       "3     343.2730   68.192323  20.6  15.7  26.8   0.0  135.0  10.1  1021.8\n",
       "4     190.1570   78.645600  21.8  14.9  27.8   0.0  177.0  10.2  1020.0\n",
       "..         ...         ...   ...   ...   ...   ...    ...   ...     ...\n",
       "772    85.2440   40.983786   3.2   0.1   5.6   0.5   89.0  11.3  1019.5\n",
       "773   163.9400   37.200143  -0.1  -1.7   2.1   0.0  277.0  10.6  1018.6\n",
       "774   282.0585   58.818259   0.1  -2.1   2.6   0.0  178.0   6.6  1026.4\n",
       "775   147.2020   37.496792   4.8  -0.8   8.3   0.5  214.0  14.8  1020.0\n",
       "776    74.6270   37.605938   5.3   2.2   8.1   5.3  269.0  12.8  1023.6\n",
       "\n",
       "[581 rows x 9 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 194.003     ,   59.39400478,   19.2       ,   13.7       ,\n",
       "         24.4       ,    0.        ,   52.        ,    8.4       ,\n",
       "       1021.5       ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# ensure all data is float\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[10,11,12,13,14,15,16,17,]], axis=1, inplace=True)\n",
    "# print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435560</td>\n",
       "      <td>0.143119</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182663</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.660969</td>\n",
       "      <td>0.347648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347648</td>\n",
       "      <td>0.181692</td>\n",
       "      <td>0.653979</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.383261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383261</td>\n",
       "      <td>0.142155</td>\n",
       "      <td>0.674740</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.626781</td>\n",
       "      <td>0.588048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.588048</td>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.889381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.377984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.377984</td>\n",
       "      <td>0.194734</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.915929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498452</td>\n",
       "      <td>0.187675</td>\n",
       "      <td>0.605413</td>\n",
       "      <td>0.486563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.180355</td>\n",
       "      <td>0.048106</td>\n",
       "      <td>0.121107</td>\n",
       "      <td>0.281746</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358543</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>0.234052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.234052</td>\n",
       "      <td>0.091874</td>\n",
       "      <td>0.121107</td>\n",
       "      <td>0.210317</td>\n",
       "      <td>0.066372</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.226006</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>0.342017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.342017</td>\n",
       "      <td>0.081541</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808050</td>\n",
       "      <td>0.198880</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>0.504066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.504066</td>\n",
       "      <td>0.140583</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.123016</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501548</td>\n",
       "      <td>0.086835</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>0.319053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.319053</td>\n",
       "      <td>0.082351</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.613003</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.605413</td>\n",
       "      <td>0.219486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1     0.435560   0.143119   0.657439   0.821429   0.734513   0.000000   \n",
       "2     0.347648   0.181692   0.653979   0.757937   0.765487   0.000000   \n",
       "3     0.383261   0.142155   0.674740   0.750000   0.809735   0.000000   \n",
       "4     0.588048   0.166184   0.723183   0.829365   0.889381   0.000000   \n",
       "5     0.377984   0.194734   0.764706   0.797619   0.915929   0.000000   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "576   0.180355   0.048106   0.121107   0.281746   0.035398   0.000000   \n",
       "577   0.234052   0.091874   0.121107   0.210317   0.066372   0.014706   \n",
       "578   0.342017   0.081541   0.006920   0.138889   0.000000   0.000000   \n",
       "579   0.504066   0.140583   0.013841   0.123016   0.013274   0.000000   \n",
       "580   0.319053   0.082351   0.176471   0.174603   0.163717   0.014706   \n",
       "\n",
       "     var7(t-1)  var8(t-1)  var9(t-1)   var1(t)  \n",
       "1     0.182663   0.252101   0.660969  0.347648  \n",
       "2     0.089783   0.184874   0.631054  0.383261  \n",
       "3     0.111455   0.137255   0.626781  0.588048  \n",
       "4     0.368421   0.184874   0.631054  0.377984  \n",
       "5     0.498452   0.187675   0.605413  0.486563  \n",
       "..         ...        ...        ...       ...  \n",
       "576   0.000000   0.358543   0.606838  0.234052  \n",
       "577   0.226006   0.218487   0.598291  0.342017  \n",
       "578   0.808050   0.198880   0.585470  0.504066  \n",
       "579   0.501548   0.086835   0.696581  0.319053  \n",
       "580   0.613003   0.316527   0.605413  0.219486  \n",
       "\n",
       "[580 rows x 10 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435560</td>\n",
       "      <td>0.143119</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182663</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.660969</td>\n",
       "      <td>0.347648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347648</td>\n",
       "      <td>0.181692</td>\n",
       "      <td>0.653979</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.383261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383261</td>\n",
       "      <td>0.142155</td>\n",
       "      <td>0.674740</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.626781</td>\n",
       "      <td>0.588048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.588048</td>\n",
       "      <td>0.166184</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.889381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.377984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.377984</td>\n",
       "      <td>0.194734</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.915929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498452</td>\n",
       "      <td>0.187675</td>\n",
       "      <td>0.605413</td>\n",
       "      <td>0.486563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.435560   0.143119   0.657439   0.821429   0.734513        0.0   \n",
       "2   0.347648   0.181692   0.653979   0.757937   0.765487        0.0   \n",
       "3   0.383261   0.142155   0.674740   0.750000   0.809735        0.0   \n",
       "4   0.588048   0.166184   0.723183   0.829365   0.889381        0.0   \n",
       "5   0.377984   0.194734   0.764706   0.797619   0.915929        0.0   \n",
       "\n",
       "   var7(t-1)  var8(t-1)  var9(t-1)   var1(t)  \n",
       "1   0.182663   0.252101   0.660969  0.347648  \n",
       "2   0.089783   0.184874   0.631054  0.383261  \n",
       "3   0.111455   0.137255   0.626781  0.588048  \n",
       "4   0.368421   0.184874   0.631054  0.377984  \n",
       "5   0.498452   0.187675   0.605413  0.486563  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 1, 9) (406,) (174, 1, 9) (174,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "#70% training data\n",
    "n_train_hours = 406\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 406 samples, validate on 174 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.3304 - val_loss: 0.2287\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.2600 - val_loss: 0.1647\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.1884 - val_loss: 0.1009\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.1236 - val_loss: 0.0681\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0983 - val_loss: 0.0740\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0995 - val_loss: 0.0816\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.1002 - val_loss: 0.0791\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0962 - val_loss: 0.0724\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0923 - val_loss: 0.0673\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0911 - val_loss: 0.0650\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0906 - val_loss: 0.0642\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0898 - val_loss: 0.0644\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0888 - val_loss: 0.0650\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0878 - val_loss: 0.0656\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0871 - val_loss: 0.0655\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0864 - val_loss: 0.0646\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0856 - val_loss: 0.0639\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0850 - val_loss: 0.0636\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0845 - val_loss: 0.0635\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0839 - val_loss: 0.0634\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0834 - val_loss: 0.0634\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0829 - val_loss: 0.0632\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0824 - val_loss: 0.0630\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0819 - val_loss: 0.0626\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0815 - val_loss: 0.0623\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0812 - val_loss: 0.0622\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0809 - val_loss: 0.0623\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0806 - val_loss: 0.0625\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0804 - val_loss: 0.0627\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0802 - val_loss: 0.0628\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0800 - val_loss: 0.0628\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0799 - val_loss: 0.0628\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0797 - val_loss: 0.0630\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0796 - val_loss: 0.0633\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0795 - val_loss: 0.0635\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0795 - val_loss: 0.0634\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0793 - val_loss: 0.0632\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0793 - val_loss: 0.0631\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0792 - val_loss: 0.0632\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0791 - val_loss: 0.0632\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0791 - val_loss: 0.0631\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0790 - val_loss: 0.0631\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0789 - val_loss: 0.0630\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0788 - val_loss: 0.0629\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0788 - val_loss: 0.0628\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0787 - val_loss: 0.0631\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0787 - val_loss: 0.0634\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0787 - val_loss: 0.0635\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0786 - val_loss: 0.0636\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0786 - val_loss: 0.0637\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 61.970\n",
      "Mean absolute error: 46.44\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(inv_y,inv_yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
