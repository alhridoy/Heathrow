{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's first load the data and take a look at what we have.\n",
    "df = pd.read_csv('heathrow_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date'], \n",
    "               axis=1,\n",
    "              inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nox_tropo</th>\n",
       "      <th>Nox_ground</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>Hum</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.12</td>\n",
       "      <td>59.75</td>\n",
       "      <td>18.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>58.67</td>\n",
       "      <td>21.35</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.395833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.04</td>\n",
       "      <td>73.87</td>\n",
       "      <td>18.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.83</td>\n",
       "      <td>25.76</td>\n",
       "      <td>34.37</td>\n",
       "      <td>14.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194.00</td>\n",
       "      <td>59.39</td>\n",
       "      <td>19.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>65.33</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36.05</td>\n",
       "      <td>20.891667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343.27</td>\n",
       "      <td>68.19</td>\n",
       "      <td>20.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>65.00</td>\n",
       "      <td>16.71</td>\n",
       "      <td>42.57</td>\n",
       "      <td>22.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.16</td>\n",
       "      <td>78.65</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>59.58</td>\n",
       "      <td>26.03</td>\n",
       "      <td>38.74</td>\n",
       "      <td>17.279167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>85.24</td>\n",
       "      <td>40.98</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>84.79</td>\n",
       "      <td>10.20</td>\n",
       "      <td>25.35</td>\n",
       "      <td>7.420833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>163.94</td>\n",
       "      <td>37.20</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>91.63</td>\n",
       "      <td>6.15</td>\n",
       "      <td>27.77</td>\n",
       "      <td>15.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>282.06</td>\n",
       "      <td>58.82</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1026.4</td>\n",
       "      <td>94.25</td>\n",
       "      <td>17.17</td>\n",
       "      <td>32.50</td>\n",
       "      <td>13.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>147.20</td>\n",
       "      <td>37.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>86.63</td>\n",
       "      <td>8.21</td>\n",
       "      <td>25.78</td>\n",
       "      <td>6.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>74.63</td>\n",
       "      <td>37.61</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1023.6</td>\n",
       "      <td>78.79</td>\n",
       "      <td>8.37</td>\n",
       "      <td>25.99</td>\n",
       "      <td>9.929167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nox_tropo  Nox_ground  tavg  tmin  tmax  prcp  wdir  wspd    pres    Hum  \\\n",
       "0       232.12       59.75  18.7  15.5  22.6   0.0     2  12.5  1023.9  58.67   \n",
       "1       168.04       73.87  18.6  13.9  23.4   0.0     1  10.1  1021.8  65.83   \n",
       "2       194.00       59.39  19.2  13.7  24.4   0.0     2   8.4  1021.5  65.33   \n",
       "3       343.27       68.19  20.6  15.7  26.8   0.0     2  10.1  1021.8  65.00   \n",
       "4       190.16       78.65  21.8  14.9  27.8   0.0     3  10.2  1020.0  59.58   \n",
       "..         ...         ...   ...   ...   ...   ...   ...   ...     ...    ...   \n",
       "575      85.24       40.98   3.2   0.1   5.6   0.5     2  11.3  1019.5  84.79   \n",
       "576     163.94       37.20  -0.1  -1.7   2.1   0.0     4  10.6  1018.6  91.63   \n",
       "577     282.06       58.82   0.1  -2.1   2.6   0.0     3   6.6  1026.4  94.25   \n",
       "578     147.20       37.50   4.8  -0.8   8.3   0.5     3  14.8  1020.0  86.63   \n",
       "579      74.63       37.61   5.3   2.2   8.1   5.3     4  12.8  1023.6  78.79   \n",
       "\n",
       "        NO    NO2       PM10  \n",
       "0    21.35  27.00  12.395833  \n",
       "1    25.76  34.37  14.937500  \n",
       "2    15.23  36.05  20.891667  \n",
       "3    16.71  42.57  22.316667  \n",
       "4    26.03  38.74  17.279167  \n",
       "..     ...    ...        ...  \n",
       "575  10.20  25.35   7.420833  \n",
       "576   6.15  27.77  15.304167  \n",
       "577  17.17  32.50  13.537500  \n",
       "578   8.21  25.78   6.412500  \n",
       "579   8.37  25.99   9.929167  \n",
       "\n",
       "[577 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Nox_tropo'], axis=1).values\n",
    "y = df['Nox_tropo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "n_hours = 1\n",
    "n_features = 13\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours , 6)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,\n",
    "                               52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72]], axis=1, inplace=True)\n",
    "# print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var1(t-1)', 'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var5(t-1)',\n",
       "       'var6(t-1)', 'var7(t-1)', 'var8(t-1)', 'var9(t-1)', 'var10(t-1)',\n",
       "       'var11(t-1)', 'var12(t-1)', 'var13(t-1)', 'var9(t+4)', 'var10(t+4)',\n",
       "       'var11(t+4)', 'var12(t+4)', 'var13(t+4)', 'var1(t+5)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 13) 460 (460,)\n",
      "(460, 1, 13) (460,) (111, 1, 13) (111,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "#80% training data\n",
    "n_train_hours = 460\n",
    "train = values[:n_train_hours]\n",
    "test = values[n_train_hours:]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# train = data.values[:459]\n",
    "# test = data.values[459:]\n",
    "\n",
    "# # Separate input and output\n",
    "# train_X, train_y = train[:, :-1], train[:, -1]\n",
    "# test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# # Reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# # Print all shapes\n",
    "# train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "154/154 - 3s - loss: 0.1513 - val_loss: 0.0544\n",
      "Epoch 2/50\n",
      "154/154 - 0s - loss: 0.0279 - val_loss: 0.0214\n",
      "Epoch 3/50\n",
      "154/154 - 0s - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 4/50\n",
      "154/154 - 0s - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 5/50\n",
      "154/154 - 0s - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      "154/154 - 0s - loss: 9.8863e-04 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "154/154 - 0s - loss: 7.5675e-04 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "154/154 - 0s - loss: 6.0704e-04 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "154/154 - 0s - loss: 4.9947e-04 - val_loss: 0.0018\n",
      "Epoch 10/50\n",
      "154/154 - 0s - loss: 4.1417e-04 - val_loss: 0.0016\n",
      "Epoch 11/50\n",
      "154/154 - 0s - loss: 3.5462e-04 - val_loss: 0.0014\n",
      "Epoch 12/50\n",
      "154/154 - 0s - loss: 3.0767e-04 - val_loss: 0.0012\n",
      "Epoch 13/50\n",
      "154/154 - 0s - loss: 2.6846e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "154/154 - 0s - loss: 2.3629e-04 - val_loss: 9.5521e-04\n",
      "Epoch 15/50\n",
      "154/154 - 0s - loss: 2.0959e-04 - val_loss: 8.4518e-04\n",
      "Epoch 16/50\n",
      "154/154 - 0s - loss: 1.8397e-04 - val_loss: 7.4982e-04\n",
      "Epoch 17/50\n",
      "154/154 - 0s - loss: 1.5897e-04 - val_loss: 6.6573e-04\n",
      "Epoch 18/50\n",
      "154/154 - 0s - loss: 1.3931e-04 - val_loss: 6.1513e-04\n",
      "Epoch 19/50\n",
      "154/154 - 0s - loss: 1.2324e-04 - val_loss: 5.7089e-04\n",
      "Epoch 20/50\n",
      "154/154 - 0s - loss: 1.1197e-04 - val_loss: 5.3518e-04\n",
      "Epoch 21/50\n",
      "154/154 - 0s - loss: 1.0218e-04 - val_loss: 4.9768e-04\n",
      "Epoch 22/50\n",
      "154/154 - 0s - loss: 9.4224e-05 - val_loss: 4.6794e-04\n",
      "Epoch 23/50\n",
      "154/154 - 0s - loss: 8.7234e-05 - val_loss: 4.4129e-04\n",
      "Epoch 24/50\n",
      "154/154 - 0s - loss: 8.1917e-05 - val_loss: 4.2508e-04\n",
      "Epoch 25/50\n",
      "154/154 - 0s - loss: 8.0291e-05 - val_loss: 4.0589e-04\n",
      "Epoch 26/50\n",
      "154/154 - 0s - loss: 7.9310e-05 - val_loss: 3.8628e-04\n",
      "Epoch 27/50\n",
      "154/154 - 0s - loss: 8.0226e-05 - val_loss: 3.6732e-04\n",
      "Epoch 28/50\n",
      "154/154 - 0s - loss: 8.0751e-05 - val_loss: 3.5181e-04\n",
      "Epoch 29/50\n",
      "154/154 - 0s - loss: 8.1951e-05 - val_loss: 3.4056e-04\n",
      "Epoch 30/50\n",
      "154/154 - 0s - loss: 7.9944e-05 - val_loss: 3.2485e-04\n",
      "Epoch 31/50\n",
      "154/154 - 0s - loss: 7.6254e-05 - val_loss: 3.1313e-04\n",
      "Epoch 32/50\n",
      "154/154 - 0s - loss: 7.0651e-05 - val_loss: 3.0124e-04\n",
      "Epoch 33/50\n",
      "154/154 - 0s - loss: 6.5793e-05 - val_loss: 2.8899e-04\n",
      "Epoch 34/50\n",
      "154/154 - 0s - loss: 6.0209e-05 - val_loss: 2.7737e-04\n",
      "Epoch 35/50\n",
      "154/154 - 0s - loss: 5.4589e-05 - val_loss: 2.6941e-04\n",
      "Epoch 36/50\n",
      "154/154 - 0s - loss: 5.0069e-05 - val_loss: 2.5822e-04\n",
      "Epoch 37/50\n",
      "154/154 - 0s - loss: 4.7673e-05 - val_loss: 2.4680e-04\n",
      "Epoch 38/50\n",
      "154/154 - 0s - loss: 4.5204e-05 - val_loss: 2.3542e-04\n",
      "Epoch 39/50\n",
      "154/154 - 0s - loss: 4.4697e-05 - val_loss: 2.2901e-04\n",
      "Epoch 40/50\n",
      "154/154 - 0s - loss: 4.6459e-05 - val_loss: 2.1967e-04\n",
      "Epoch 41/50\n",
      "154/154 - 0s - loss: 4.5547e-05 - val_loss: 2.0709e-04\n",
      "Epoch 42/50\n",
      "154/154 - 0s - loss: 4.3714e-05 - val_loss: 1.9679e-04\n",
      "Epoch 43/50\n",
      "154/154 - 0s - loss: 4.3958e-05 - val_loss: 1.9562e-04\n",
      "Epoch 44/50\n",
      "154/154 - 0s - loss: 4.5571e-05 - val_loss: 1.9017e-04\n",
      "Epoch 45/50\n",
      "154/154 - 0s - loss: 4.5907e-05 - val_loss: 1.9299e-04\n",
      "Epoch 46/50\n",
      "154/154 - 0s - loss: 4.7769e-05 - val_loss: 1.9428e-04\n",
      "Epoch 47/50\n",
      "154/154 - 0s - loss: 5.3860e-05 - val_loss: 1.7184e-04\n",
      "Epoch 48/50\n",
      "154/154 - 0s - loss: 4.9487e-05 - val_loss: 1.6777e-04\n",
      "Epoch 49/50\n",
      "154/154 - 0s - loss: 4.7591e-05 - val_loss: 1.8497e-04\n",
      "Epoch 50/50\n",
      "154/154 - 0s - loss: 7.2656e-05 - val_loss: 1.6999e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(13, input_shape=(train_X.shape[1], train_X.shape[2]),activation='relu'))\n",
    "model.add(Dense(38, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=3, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 8.352\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -12:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -12:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7128026774990674"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(inv_y,inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.238986627331904"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(inv_y,inv_yhat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13-38-1 Test RMSE: 62.006\n",
    "\n",
    "13-68-1 Test RMSE: 68.752"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 61-1 Test RMSE: Test RMSE: 63.163\n",
    "\n",
    "13-40-1 Test RMSE: 67.366\n",
    "\n",
    "13-100-1 Test RMSE: 65.965\n",
    "\n",
    "13- -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
